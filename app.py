import os
from dotenv import load_dotenv
import streamlit as st
from openai import AzureOpenAI

# -----------------------
# 0. ê¸°ë³¸ ì„¤ì •
# -----------------------
load_dotenv()

st.set_page_config(
    page_title="ë‚˜ì˜ ì²« AI ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide",
)

# -----------------------
# 1. Azure OpenAI í´ë¼ì´ì–¸íŠ¸
# -----------------------
client = AzureOpenAI(
    api_key=os.getenv("AZURE_OAI_KEY"),
    api_version="2024-05-01-preview",
    azure_endpoint=os.getenv("AZURE_OAI_ENDPOINT"),
)

# -----------------------
# 2. Session State ì´ˆê¸°í™”
# -----------------------
if "messages" not in st.session_state:
    st.session_state.messages = []

if "system_prompt" not in st.session_state:
    st.session_state.system_prompt = "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê²Œ ëŒ€ë‹µí•˜ëŠ” í•œêµ­ì–´ AI ë¹„ì„œì…ë‹ˆë‹¤."

if "temperature" not in st.session_state:
    st.session_state.temperature = 0.7

# -----------------------
# 3. ì‚¬ì´ë“œë°” (ê¾¸ë¯¸ê¸° + ì„¤ì •)
# -----------------------
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    st.markdown("**ğŸ§  AI ì—­í•  ì„¤ì •**")
    system_prompt_input = st.text_area(
        "ì‹œìŠ¤í…œ ë©”ì‹œì§€",
        value=st.session_state.system_prompt,
        height=100,
        label_visibility="collapsed",
    )
    st.session_state.system_prompt = system_prompt_input

    # ì˜¨ë„ ìŠ¬ë¼ì´ë”
    st.markdown("**ğŸ”¥ ì°½ì˜ì„±(temperature)**")
    temp = st.slider("ì°½ì˜ì„±", 0.0, 1.5, st.session_state.temperature, 0.1)
    st.session_state.temperature = temp

    st.markdown("---")

    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ§¹ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.experimental_rerun()

# -----------------------
# 4. ë©”ì¸ í™”ë©´ í—¤ë”
# -----------------------
st.title("ğŸ¤– ë‚˜ì˜ ì²« AI ì±—ë´‡")
st.caption("Azure OpenAI + Streamlit ë°ëª¨")

# -----------------------
# 5. ì´ì „ ëŒ€í™” ì¶œë ¥
# -----------------------
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# -----------------------
# 6. ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
# -----------------------
if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
    # 1) ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ & ì €ì¥
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 2) AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ìƒê° ì¤‘..."):
            # system ë©”ì‹œì§€ + ì§€ê¸ˆê¹Œì§€ ëŒ€í™” ëª¨ì•„ì„œ ë³´ëƒ„
            messages_for_api = [
                {"role": "system", "content": st.session_state.system_prompt},
                *st.session_state.messages,
            ]

            response = client.chat.completions.create(
                model="gpt-4o-mini",  # ë°°í¬ ì´ë¦„
                messages=messages_for_api,
                temperature=st.session_state.temperature,
            )
            assistant_reply = response.choices[0].message.content

            st.markdown(assistant_reply)

    # 3) AI ì‘ë‹µ ì €ì¥
    st.session_state.messages.append(
        {"role": "assistant", "content": assistant_reply}
    )
